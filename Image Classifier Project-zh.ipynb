{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开发 AI 应用\n",
    "\n",
    "未来，AI 算法在日常生活中的应用将越来越广泛。例如，你可能想要在智能手机应用中包含图像分类器。为此，在整个应用架构中，你将使用一个用成百上千个图像训练过的深度学习模型。未来的软件开发很大一部分将是使用这些模型作为应用的常用部分。\n",
    "\n",
    "在此项目中，你将训练一个图像分类器来识别不同的花卉品种。可以想象有这么一款手机应用，当你对着花卉拍摄时，它能够告诉你这朵花的名称。在实际操作中，你会训练此分类器，然后导出它以用在你的应用中。我们将使用[此数据集](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html)，其中包含 102 个花卉类别。你可以在下面查看几个示例。 \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "该项目分为多个步骤：\n",
    "\n",
    "* 加载和预处理图像数据集\n",
    "* 用数据集训练图像分类器\n",
    "* 使用训练的分类器预测图像内容\n",
    "\n",
    "我们将指导你完成每一步，你将用 Python 实现这些步骤。\n",
    "\n",
    "完成此项目后，你将拥有一个可以用任何带标签图像的数据集进行训练的应用。你的网络将学习花卉，并成为一个命令行应用。但是，你对新技能的应用取决于你的想象力和构建数据集的精力。例如，想象有一款应用能够拍摄汽车，告诉你汽车的制造商和型号，然后查询关于该汽车的信息。构建你自己的数据集并开发一款新型应用吧。\n",
    "\n",
    "首先，导入你所需的软件包。建议在代码开头导入所有软件包。当你创建此 notebook 时，如果发现你需要导入某个软件包，确保在开头导入该软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import seaborn as sb\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据\n",
    "\n",
    "在此项目中，你将使用 `torchvision` 加载数据（[文档](http://pytorch.org/docs/master/torchvision/transforms.html#)）。数据应该和此 notebook 一起包含在内，否则你可以[在此处下载数据](https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz)。数据集分成了三部分：训练集、验证集和测试集。对于训练集，你需要变换数据，例如随机缩放、剪裁和翻转。这样有助于网络泛化，并带来更好的效果。你还需要确保将输入数据的大小调整为 224x224 像素，因为预训练的网络需要这么做。\n",
    "\n",
    "验证集和测试集用于衡量模型对尚未见过的数据的预测效果。对此步骤，你不需要进行任何缩放或旋转变换，但是需要将图像剪裁到合适的大小。\n",
    "\n",
    "对于所有三个数据集，你都需要将均值和标准差标准化到网络期望的结果。均值为 `[0.485, 0.456, 0.406]`，标准差为 `[0.229, 0.224, 0.225]`。这样使得每个颜色通道的值位于 -1 到 1 之间，而不是 0 到 1 之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "valid_dir = 'valid'\n",
    "test_dir = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(0.25),\n",
    "                                     transforms.RandomRotation(30),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize( (0.485, 0.456, 0.406),\n",
    "                                                           (0.229, 0.224, 0.225))])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize( (0.485, 0.456, 0.406),\n",
    "                                                           (0.229, 0.224, 0.225))])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_datasets = datasets.ImageFolder('flowers' + '/'+ train_dir, transform=train_transforms)\n",
    "valid_datasets = datasets.ImageFolder('flowers' + '/'+ valid_dir, transform=valid_transforms)\n",
    "test_datasets = datasets.ImageFolder('flowers/' + '/'+ test_dir, transform=train_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_datasets, batch_size=64, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_datasets, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_datasets, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签映射\n",
    "\n",
    "你还需要加载从类别标签到类别名称的映射。你可以在文件 `cat_to_name.json` 中找到此映射。它是一个 JSON 对象，可以使用 [`json` 模块](https://docs.python.org/2/library/json.html)读取它。这样可以获得一个从整数编码的类别到实际花卉名称的映射字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建和训练分类器\n",
    "\n",
    "数据准备好后，就开始构建和训练分类器了。和往常一样，你应该使用 `torchvision.models` 中的某个预训练模型获取图像特征。使用这些特征构建和训练新的前馈分类器。\n",
    "\n",
    "这部分将由你来完成。如果你想与他人讨论这部分，欢迎与你的同学讨论！你还可以在论坛上提问或在工作时间内咨询我们的课程经理和助教导师。\n",
    "\n",
    "请参阅[审阅标准](https://review.udacity.com/#!/rubrics/1663/view)，了解如何成功地完成此部分。你需要执行以下操作：\n",
    "\n",
    "* 加载[预训练的网络](http://pytorch.org/docs/master/torchvision/models.html)（如果你需要一个起点，推荐使用 VGG 网络，它简单易用）\n",
    "* 使用 ReLU 激活函数和丢弃定义新的未训练前馈网络作为分类器\n",
    "* 使用反向传播训练分类器层，并使用预训练的网络获取特征\n",
    "* 跟踪验证集的损失和准确率，以确定最佳超参数\n",
    "\n",
    "我们在下面为你留了一个空的单元格，但是你可以使用多个单元格。建议将问题拆分为更小的部分，并单独运行。检查确保每部分都达到预期效果，然后再完成下个部分。你可能会发现，当你实现每部分时，可能需要回去修改之前的代码，这很正常！\n",
    "\n",
    "训练时，确保仅更新前馈网络的权重。如果一切构建正确的话，验证准确率应该能够超过 70%。确保尝试不同的超参数（学习速率、分类器中的单元、周期等），寻找最佳模型。保存这些超参数并用作项目下个部分的默认值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build and train your network\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model = models.densenet121(pretrained = True)\n",
    "model.name = 'densenet121'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): classifier(\n",
       "    (hidden_layers): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (output): Linear(in_features=512, out_features=102, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad= False\n",
    "\n",
    "# hyperparameters for classifier\n",
    "input_size = [each.in_features for each in model.classifier.modules() if type(each) == torch.nn.modules.linear.Linear][0]\n",
    "hidden_layers = [512]\n",
    "output_size = 102\n",
    "drop_p = 0.5\n",
    "epochs = 30\n",
    "\n",
    "# Adding own classifier\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        if len(hidden_layers) > 1:\n",
    "            layers = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "            self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layers])\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model.classifier = classifier(input_size, output_size, hidden_layers, drop_p)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# validation test\n",
    "def validation(model, criterion, validloader):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for images, targets in iter(validloader):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        loss += criterion(output, targets).item()\n",
    "        \n",
    "        ps = torch.exp(output)\n",
    "        equality = (targets.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, trainloader, validloader, criterion, optimizer, print_step=32, epochs=5):\n",
    "    \n",
    "    # training\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    print_step = 32\n",
    "    \n",
    "    # validation result variables\n",
    "    vloss = 0\n",
    "    vaccuracy = 0\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for images, labels in iter(trainloader):\n",
    "            steps += 1\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps%print_step == 0:\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    vloss, vaccuracy = validation(model, criterion, validloader)\n",
    "\n",
    "                print('Epoch: {}/{}\\t'.format(e+1, epochs),\n",
    "                      'Train Loss: {:.3f}\\t'.format(running_loss/print_step),\n",
    "                      'Valid Loss: {:.3f}\\t'.format(vloss/len(validloader)),\n",
    "                      'Valid Accuracy: {:.3f}'.format(vaccuracy/len(validloader)*100))\n",
    "\n",
    "                running_loss = 0\n",
    "\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\t Train Loss: 4.406\t Valid Loss: 4.009\t Valid Accuracy: 16.795\n",
      "Epoch: 1/5\t Train Loss: 3.802\t Valid Loss: 3.322\t Valid Accuracy: 27.499\n",
      "Epoch: 1/5\t Train Loss: 3.134\t Valid Loss: 2.619\t Valid Accuracy: 46.571\n",
      "Epoch: 2/5\t Train Loss: 2.621\t Valid Loss: 2.201\t Valid Accuracy: 51.341\n",
      "Epoch: 2/5\t Train Loss: 2.250\t Valid Loss: 1.902\t Valid Accuracy: 55.554\n",
      "Epoch: 2/5\t Train Loss: 1.990\t Valid Loss: 1.645\t Valid Accuracy: 64.094\n",
      "Epoch: 3/5\t Train Loss: 1.835\t Valid Loss: 1.487\t Valid Accuracy: 66.289\n",
      "Epoch: 3/5\t Train Loss: 1.644\t Valid Loss: 1.340\t Valid Accuracy: 69.623\n",
      "Epoch: 3/5\t Train Loss: 1.602\t Valid Loss: 1.299\t Valid Accuracy: 71.110\n",
      "Epoch: 4/5\t Train Loss: 1.446\t Valid Loss: 1.164\t Valid Accuracy: 74.273\n",
      "Epoch: 4/5\t Train Loss: 1.389\t Valid Loss: 1.094\t Valid Accuracy: 74.424\n",
      "Epoch: 4/5\t Train Loss: 1.267\t Valid Loss: 1.018\t Valid Accuracy: 76.948\n",
      "Epoch: 5/5\t Train Loss: 1.262\t Valid Loss: 1.060\t Valid Accuracy: 73.147\n",
      "Epoch: 5/5\t Train Loss: 1.191\t Valid Loss: 0.980\t Valid Accuracy: 77.916\n",
      "Epoch: 5/5\t Train Loss: 1.133\t Valid Loss: 0.928\t Valid Accuracy: 76.752\n",
      "Epoch: 5/5\t Train Loss: 1.186\t Valid Loss: 0.950\t Valid Accuracy: 76.872\n"
     ]
    }
   ],
   "source": [
    "train(model.to(device), trainloader, testloader, criterion, optimizer, print_step=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试网络\n",
    "\n",
    "建议使用网络在训练或验证过程中从未见过的测试数据测试训练的网络。这样，可以很好地判断模型预测全新图像的效果。用网络预测测试图像，并测量准确率，就像验证过程一样。如果模型训练良好的话，你应该能够达到大约 70% 的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do validation on the test set\n",
    "def test(model, criterion, testloader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tloss, taccuracy = validation(model, criterion, testloader)\n",
    "\n",
    "    print('Test Accuracy: {:.3f}'.format(taccuracy/len(testloader)*100))\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.435\n"
     ]
    }
   ],
   "source": [
    "test(model.to(device), criterion, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存检查点\n",
    "\n",
    "训练好网络后，保存模型，以便稍后加载它并进行预测。你可能还需要保存其他内容，例如从类别到索引的映射，索引是从某个图像数据集中获取的：`image_datasets['train'].class_to_idx`。你可以将其作为属性附加到模型上，这样稍后推理会更轻松。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "attributes": {
     "": "",
     "classes": [],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#注意，稍后你需要完全重新构建模型，以便用模型进行推理。确保在检查点中包含你所需的任何信息。如果你想加载模型并继续训练，则需要保存周期数量和优化器状态 `optimizer.state_dict`。你可能需要在下面的下个部分使用训练的模型，因此建议立即保存它。\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Save the checkpoint \n",
    "model.class_to_idx = train_datasets.class_to_idx\n",
    "\n",
    "checkpoint = {\n",
    "    'input_size': input_size,\n",
    "    'output_size': output_size,\n",
    "    'hidden_layer_size': [each.out_features for each in model.classifier.hidden_layers],\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'class_to_idx': model.class_to_idx,\n",
    "    'drop_p': drop_p,\n",
    "    'learning_rate': learning_rate,\n",
    "    'epochs': epochs,\n",
    "    'model': model.name\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, \n",
    "           'checkpoint_{}_{}.pth'.format(\n",
    "            \"_\".join([str(each.out_features) for each in  model.classifier.hidden_layers]), checkpoint['model']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载检查点\n",
    "\n",
    "此刻，建议写一个可以加载检查点并重新构建模型的函数。这样的话，你可以回到此项目并继续完善它，而不用重新训练网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = getattr(models, checkpoint['model'])(pretrained=True)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model.classifier = classifier(checkpoint['input_size'],\n",
    "                                 checkpoint['output_size'],\n",
    "                                 checkpoint['hidden_layer_size'],\n",
    "                                 checkpoint['drop_p'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=checkpoint['learning_rate'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "    \n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.cuda()\n",
    "    \n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类别推理\n",
    "\n",
    "现在，你需要写一个使用训练的网络进行推理的函数。即你将向网络中传入一个图像，并预测图像中的花卉类别。写一个叫做 `predict` 的函数，该函数会接受图像和模型，然后返回概率在前 $K$ 的类别及其概率。应该如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-321d8d2fa235>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-321d8d2fa235>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    > [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，你需要处理输入图像，使其可以用于你的网络。\n",
    "\n",
    "## 图像处理\n",
    "\n",
    "你需要使用 `PIL` 加载图像（[文档](https://pillow.readthedocs.io/en/latest/reference/Image.html)）。建议写一个函数来处理图像，使图像可以作为模型的输入。该函数应该按照训练的相同方式处理图像。\n",
    "\n",
    "首先，调整图像大小，使最小的边为 256 像素，并保持宽高比。为此，可以使用 [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) 或 [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) 方法。然后，你需要从图像的中心裁剪出 224x224 的部分。\n",
    "\n",
    "图像的颜色通道通常编码为整数 0-255，但是该模型要求值为浮点数 0-1。你需要变换值。使用 Numpy 数组最简单，你可以从 PIL 图像中获取，例如 `np_image = np.array(pil_image)`。\n",
    "\n",
    "和之前一样，网络要求图像按照特定的方式标准化。均值应标准化为 `[0.485, 0.456, 0.406]`，标准差应标准化为 `[0.229, 0.224, 0.225]`。你需要用每个颜色通道减去均值，然后除以标准差。\n",
    "\n",
    "最后，PyTorch 要求颜色通道为第一个维度，但是在 PIL 图像和 Numpy 数组中是第三个维度。你可以使用 [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html)对维度重新排序。颜色通道必须是第一个维度，并保持另外两个维度的顺序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    img = Image.open(image)\n",
    "    \n",
    "    tsize = (256, 256)\n",
    "    img.thumbnail(tsize)\n",
    "\n",
    "    lwsize = (img.size[0] - 224)/2\n",
    "    thsize = (img.size[1] - 224)/2\n",
    "    rwsize = (img.size[0] + 224)/2\n",
    "    bhsize = (img.size[1] + 224)/2\n",
    "    \n",
    "    img = img.crop((lwsize, thsize, rwsize, bhsize))\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    npimg = np.array(img)\n",
    "    npimg = npimg/255\n",
    "    \n",
    "    npimg = (npimg - mean)/std\n",
    "    \n",
    "    npimg = npimg.transpose((2,0,1))\n",
    "\n",
    "    return torch.from_numpy(npimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要检查你的项目，可以使用以下函数来转换 PyTorch 张量并将其显示在  notebook 中。如果 `process_image` 函数可行，用该函数运行输出应该会返回原始图像（但是剪裁掉的部分除外）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类别预测\n",
    "\n",
    "可以获得格式正确的图像后 \n",
    "\n",
    "要获得前 $K$ 个值，在张量中使用 [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk)。该函数会返回前 `k` 个概率和对应的类别索引。你需要使用  `class_to_idx`（希望你将其添加到了模型中）将这些索引转换为实际类别标签，或者从用来加载数据的[ `ImageFolder`](https://pytorch.org/docs/master/torchvision/datasets.html?highlight=imagefolder#torchvision.datasets.ImageFolder)进行转换。确保颠倒字典\n",
    "\n",
    "同样，此方法应该接受图像路径和模型检查点，并返回概率和类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-321d8d2fa235>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-321d8d2fa235>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    > [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    imaget = process_image(image_path)\n",
    "    imaget.to(device)\n",
    "    \n",
    "    imaget = imaget.unsqueeze(0)\n",
    "    image = imaget.type(torch.cuda.FloatTensor)\n",
    "    output = model.forward(image)\n",
    "    ps = torch.exp(output)\n",
    "    model.train()\n",
    "    return ps.topk(topk)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查运行状况\n",
    "\n",
    "你已经可以使用训练的模型做出预测，现在检查模型的性能如何。即使测试准确率很高，始终有必要检查是否存在明显的错误。使用 `matplotlib` 将前 5 个类别的概率以及输入图像绘制为条形图，应该如下所示：\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "你可以使用 `cat_to_name.json` 文件（应该之前已经在 notebook 中加载该文件）将类别整数编码转换为实际花卉名称。要将 PyTorch 张量显示为图像，请使用定义如下的 `imshow` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc61c00a7b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Display an image along with the top 5 classes\n",
    "\n",
    "image_path = 'flowers/test/28/image_05230.jpg'\n",
    "\n",
    "probs, labels = predict(image_path, model)\n",
    "\n",
    "ps = [x for x in probs.cpu().detach().numpy()[0]]\n",
    "npar = [x for x in labels.cpu().numpy()[0]]\n",
    "names = list()\n",
    "\n",
    "inv_mapping = {v: k for k, v in model.class_to_idx.items()}\n",
    "\n",
    "for i in npar:\n",
    "    names.append(cat_to_name[str(inv_mapping[i])])\n",
    "\n",
    "\n",
    "imshow(process_image(image_path), ax=plt.subplot(2,1,1));\n",
    "plt.title(cat_to_name['28'])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sb.barplot(y=names, x=ps, color=sb.color_palette()[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
